---
flink:
  streamTimeCharacteristic: "ProcessingTime" # ProcessingTime|IngestionTime|EventTime
  job:
    groupId: "${spring.application.name}-group"
    name: "${spring.application.name}"
    parallelism: "1"

kafka:
  bootstrapServers: "localhost:9092"
  zookeeperConnect: "localhost:2181"
  events: # Event will have a main source stream which will be split into multiple substreams based on the below configuration of substream list per source.
    sources:
      - topic: "log-event-stream-input" ## log file structure
        siddhiStreamName: "logInputStream"
        substreams:
          - streamName: "s3-access-log" ## final Substream name will be logInputStream-s3-access-log
            type: "s3.access.log"
            serde: ""
        sink:
          topic: "json-event-stream-output"
          outputStreamName: "outputstream"
  rules: # Rule will have a main source stream which will be split into multiple substreams based on the below configuration of substream list per source.
    sources: ## Always will be a json data from any source
      - topic: "si-simple-rules" # Main topic/source name where rules control events are published
        controlStreamName: "simplerulesStream"
        mappingSourceDataStream : "${kafka.events.sources[0].siddhiStreamName}" #NOTE: This has to match with one of the
                                                                                # kafka.events.sources.[x].siddhiStreamName
        subStreams:
          - streamName: "s3-access-log" ## final rule Substream name will be logInputStream-s3-access-log, this is needed to
                                        # map the rule substream with the data substream which catter to common types.
            type: "s3.access.log"

spring:
  application:
    name: "SIFlinkJob"
...